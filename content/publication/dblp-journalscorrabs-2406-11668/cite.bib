@article{DBLP:journals/corr/abs-2406-11668,
 author = {Lingrui Mei and
Shenghua Liu and
Yiwei Wang and
Baolong Bi and
Jiayi Mao and
Xueqi Cheng},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/journals/corr/abs-2406-11668.bib},
 doi = {10.48550/ARXIV.2406.11668},
 eprint = {2406.11668},
 eprinttype = {arXiv},
 journal = {CoRR},
 timestamp = {Tue, 04 Feb 2025 00:00:00 +0100},
 title = {"Not Aligned" is Not "Malicious": Being Careful about Hallucinations
of Large Language Models' Jailbreak},
 url = {https://doi.org/10.48550/arXiv.2406.11668},
 volume = {abs/2406.11668},
 year = {2024}
}
