---
title: "\\\" Not Aligned\\\" is Not\\\" Malicious\\\": Being Careful about Hallucinations
  of Large Language Models' Jailbreak"
authors:
- Lingrui Mei
- Shenghua Liu
- Yiwei Wang
- Baolong Bi
- Jiayi Mao
- Xueqi Cheng
date: '2024-01-01'
publishDate: '2025-05-06T15:47:20.809655Z'
publication_types:
- article-journal
publication: '*arXiv preprint arXiv:2406.11668*'
---
